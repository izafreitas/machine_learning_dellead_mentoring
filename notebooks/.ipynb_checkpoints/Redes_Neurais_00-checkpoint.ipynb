{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e945b39c",
   "metadata": {},
   "source": [
    "# **Pratices of Neural Network in Python**\n",
    "https://people.revoledu.com/kardi/tutorial/Python/Practice+Neural+Network+in+Python.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57d8e1a",
   "metadata": {},
   "source": [
    "**Exemplo com OR Boolean**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a364bb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "import sklearn.metrics as metric\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf26c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1,1],\n",
    "            [1,0],\n",
    "            [0,1],\n",
    "            [0,0]\n",
    "           ]\n",
    "y_training=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10fd1ce",
   "metadata": {},
   "source": [
    "## **Perceptron**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b5639f",
   "metadata": {},
   "source": [
    "1. Medindo.\n",
    "2. Prevendo e medindo precisão.\n",
    "3. Fazendo previsão. \n",
    "4. Obtendo pesos da Rede Neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a75e9122",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y should be a 1d array, got an array of shape (4, 2) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-d68924e0d11c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mptn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptron\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m          \u001b[1;31m# definindo o método\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mptn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_training\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# treinando o modelo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mptn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_testing\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# fazendo a predição\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m                              \u001b[1;31m# mostrando a saída\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    727\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    728\u001b[0m         \"\"\"\n\u001b[1;32m--> 729\u001b[1;33m         return self._fit(X, y, alpha=self.alpha, C=1.0,\n\u001b[0m\u001b[0;32m    730\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[0;32m    541\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 543\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr',\n\u001b[0m\u001b[0;32m    544\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    545\u001b[0m                                    accept_large_sparse=False)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    824\u001b[0m                         ensure_2d=False, dtype=None)\n\u001b[0;32m    825\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 826\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    827\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    828\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'O'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    862\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 864\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    865\u001b[0m         \u001b[1;34m\"y should be a 1d array, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    866\u001b[0m         \"got an array of shape {} instead.\".format(shape))\n",
      "\u001b[1;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (4, 2) instead."
     ]
    }
   ],
   "source": [
    "ptn = Perceptron (max_iter = 500)          # definindo o método\n",
    "ptn.fit(X_training, y_training)            # treinando o modelo\n",
    "y_pred = ptn.predict(X_testing)            # fazendo a predição\n",
    "print(y_pred)                              # mostrando a saída\n",
    "accuracy=metric.accuracy_score(y_true, y_pred, normalize=True)\n",
    "print('acuracy=', accuracy)                # mostrando a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87044108",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Perceptron' object has no attribute 'intercept_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0ad04e9f875d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mptn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mptn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# mostrando os pesos das sinapse w0, w1, w2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Perceptron' object has no attribute 'intercept_'"
     ]
    }
   ],
   "source": [
    "print(ptn.intercept_, ptn.coef_)    # mostrando os pesos das sinapse w0, w1, w2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef99927d",
   "metadata": {},
   "source": [
    "## Multi-Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f82346",
   "metadata": {},
   "source": [
    "O código abaixo é um exemplo de como você usa o Multi-Layer Perceptron(MLP) Neural Network para treinar, predizer e medir a acuracia de sua predição. Você também pode obter os pesos da Rede Neural."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbd526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(solver='lbfgs', hidden_layer_sizes=(1,1), activation='logistic') # definindo método\n",
    "mlp.fit(X_training, y_training) # treinamento\n",
    "y_pred=mlp.predict(X_testing)   # predição\n",
    "print(y_pred)                   # mostrando a saída\n",
    "accuracy=metric.accuracy_score(np.array(y_true).flatten(), np.array(y_pred).flatten(), normalize=True)\n",
    "print('acuracy=', accuracy)     # mostrando a acurácia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d618cdc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1ae72910aaae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcoef\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# tamanho dos pesos das sinapses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoefs_\u001b[0m                                 \u001b[1;31m# pesos das sinapses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mlp' is not defined"
     ]
    }
   ],
   "source": [
    "print([coef.shape for coef in mlp.coefs_]) # tamanho dos pesos das sinapses\n",
    "mlp.coefs_                                 # pesos das sinapses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1f664d",
   "metadata": {},
   "source": [
    "## Experimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fca78a",
   "metadata": {},
   "source": [
    "- Altere os dados (X_training, y_training, X_testing)\n",
    "    - Mude binário para bipolar {-1, +1}\n",
    "- Altere a camada oculta do MLP: número de camadas (int) ou tamanho (n, m)\n",
    "- Alterar solucionador de MLP: {'lbfgs', 'sgd', 'adam'}\n",
    "- Alterar a função de ativação do MLP: {'identidade', 'logística', 'tanh', 'relu'}, padrão 'relu'\n",
    "Pontas\n",
    "\n",
    "- Verifique a precisão da previsão"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0926af8b",
   "metadata": {},
   "source": [
    "## Prática: Bipolar OU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab95e88",
   "metadata": {},
   "source": [
    "Em vez de {0, 1}, também podemos alterar o valor para bipolar {-1, +1}. Tente a seguinte porta OR usando Perceptron e MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b3988",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training = [[1, 1],\n",
    "             [ 1,-1],\n",
    "             [-1, 1],\n",
    "             [-1,-1]\n",
    "             ]\n",
    "y_training = [ 1 , \n",
    "              1, \n",
    "              1, \n",
    "             -1 \n",
    "             ]\n",
    "X_testing = X_training\n",
    "y_true = y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0126fb54",
   "metadata": {},
   "source": [
    "## Prática-2: E gate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9d4e21",
   "metadata": {},
   "source": [
    "Treine e preveja o treinamento do portão AND definido abaixo usando Perceptron e MLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85ab305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1], \n",
    "            [1, 0], \n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1, \n",
    "           0, \n",
    "           0,\n",
    "           0\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631b6400",
   "metadata": {},
   "source": [
    "## Pratica-3: Bipolar AND gate\n",
    "\n",
    "Modifique os dados de treinamento AND Booleanos acima para bipolares. Use Perceptron e MLP para treinar e prever esse portão."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e7cda",
   "metadata": {},
   "source": [
    "## Pratica-4: dois neuronios de saída\n",
    "\n",
    "Tente usar o perceptron e o MLP para treinar e predizer seguinte dataset. O que aconteceu? Por que você acha que o erro aconteceu?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "740775ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1],\n",
    "           [1, 0],\n",
    "           [0, 1],\n",
    "           [0, 0],\n",
    "           ]\n",
    "y_training=[[1, 1],\n",
    "            [1, 1],\n",
    "            [1, 1],\n",
    "            [0, 1]            \n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40c5e72",
   "metadata": {},
   "source": [
    "## Prática-5: XOR\n",
    "\n",
    "Use o Perceptron a o MLP para resolver o seguinte problema Boolean Exclusive Or (XOR). Como melhorar a acurácia? Quantas camadas ocultas mínimas são necessárias para torná-lo com 100% de precisão?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6842e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1],\n",
    "            [1, 0], \n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1,\n",
    "           0,\n",
    "           0,\n",
    "           1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c051ef",
   "metadata": {},
   "source": [
    "## Pratica-6: Tautologia\n",
    "\n",
    "Treine o PErceptron MLP para resolver a seguinte Tautoligia Booleana (todos 1). O que acontece?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3742a46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1],\n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 0]\n",
    "           ]\n",
    "y_training=[1,\n",
    "           1,\n",
    "           1,\n",
    "           1\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f6bfd6",
   "metadata": {},
   "source": [
    "## Prática-7: Boolean XNOR\n",
    "\n",
    "Use o Perceptron e MLP para resolver a seguinte problema Boolean Exclusive Not Or (XNOR). Como melhorar a acurácia? Quantas camadas ocultas mínimas são necessárias para torná-lo 100% de precisão?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e32df67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1],\n",
    "           [1, 0],\n",
    "           [0, 1],\n",
    "           [0, 0]\n",
    "          ]\n",
    "y_training=[0,\n",
    "           1,\n",
    "           1,\n",
    "           0\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d5b1a9",
   "metadata": {},
   "source": [
    "## Prática-8: Rede Neural com 3 inputs e 2 outputs\n",
    "\n",
    "Tente treinar o seguinte conjunto de dados usando rede neural. Experimente alterar o solucionador, as camadas ocultas e a função de ativação para melhorar a precisão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18d3e24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1,  1,  0],\n",
    "            [1, -1, -1],\n",
    "            [-1, 1,  1],\n",
    "            [-1, -1, 1], \n",
    "            [0,  1, -1],\n",
    "            [0, -1, -1],\n",
    "            [1,  1,  1]\n",
    "           ]\n",
    "y_training=[[1, 0],\n",
    "           [0, 1], \n",
    "           [1, 1],\n",
    "           [1, 0],\n",
    "           [1, 0],\n",
    "           [1, 1],\n",
    "           [1, 1]\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ead39",
   "metadata": {},
   "source": [
    "## Prática-9: Rede Neural para Adição\n",
    "Treine o Perceptron e o MLP para resolver o problema de adição de rede neural. O que acontece? Por que você não pode resolver esse tipo de problema simples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab7bfd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_training=[[1, 1],\n",
    "            [1, 2.5],\n",
    "            [-1, 1.5],\n",
    "            [-1,-1],\n",
    "            [0,  1],\n",
    "            [0, -1],\n",
    "            [1,  1]\n",
    "           ]\n",
    "y_training=[2,\n",
    "           3.5,\n",
    "           0.5,\n",
    "           0,\n",
    "           1,\n",
    "           -1,\n",
    "           2\n",
    "           ]\n",
    "X_testing=X_training\n",
    "y_true=y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2dc2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
