{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d466fb04",
   "metadata": {},
   "source": [
    "### Plano de Avalicação Dell Academy Trilha de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d410732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn \n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer # módulo para fazer o Bag of words\n",
    "import scipy.sparse\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, cross_val_predict \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from wordcloud import WordCloud\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "nltk.download(\"all\")\n",
    "from nltk import tokenize\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d38cac18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b334ec",
   "metadata": {},
   "source": [
    "## Leitura do dataset de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71a120f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"datasets/test.csv\")\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01624d9b-d3b5-4c09-9859-e072794f0345",
   "metadata": {},
   "source": [
    "## Leitura do dataset de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf61ea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"datasets/train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ad2d76",
   "metadata": {},
   "source": [
    "## Concatenando os datasets para otimizar a análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88caa00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido = pd.concat([df_test, df_train], ignore_index=True)\n",
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c669a2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visão resumida do DF\n",
    "df_unido.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6666610e",
   "metadata": {},
   "source": [
    "## Visão geral do DF com Pandas Profilling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5199ab5",
   "metadata": {},
   "source": [
    "**Atualizando o pandas profiling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3746bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07700f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "\n",
    "#!\"{sys.executable}\" -m pip install -U pandas-profiling[notebook]\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc935f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando biblioteca Standart\n",
    "from pathlib import Path\n",
    "\n",
    "# Instalando pacotes\n",
    "import pandas as pd\n",
    "from ipywidgets import widgets\n",
    "\n",
    "# Pacotes para trabalhar com o Profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "from pandas_profiling.utils.cache import cache_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed817f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando os relatórios do DF\n",
    "profile = ProfileReport(\n",
    "    df_unido, title=\"IMDB Dataset\", html={\"style\": {\"full_width\": True}}, sort=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4774585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A interface de widgets do notebook\n",
    "#profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81363b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usando o relatório em um HTML iframe \n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6013a10c",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "Com o relatório acima podemos concluir que os dados estão balanceados..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eab0aa8-40b7-4e10-b5d8-393f3d108592",
   "metadata": {},
   "source": [
    "**Adicionando a coluna (clf_num) para a classificação numérica dos sentimentos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23814113",
   "metadata": {},
   "source": [
    "Legenda numérica para a coluna `clf_num`\n",
    "\n",
    "Sentimento negativo = 0\n",
    "\n",
    "Sentimento positivo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5f324-dba9-4f0b-9a52-7bc1482e4136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenando na variável \"classificacao\" e substituindo os valores \"neg\" e \"pos\" da coluna sentiment pelos números 0 e 1 respectivamente\n",
    "classificacao = df_unido[\"sentiment\"]. replace([\"neg\", \"pos\"], [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1956a7d9-5db0-4816-9269-1d0937b5841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicionando a coluna \"clf_num\" ao dataframe chamando a variável \"classificacao\"\n",
    "df_unido[\"clf_num\"] = classificacao\n",
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed8925-83ec-4c17-a332-d6adbb79e096",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb53655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soma dos valores NaN em relação as linhas (por isso o shape está setado em 0), multiplicado por 100\n",
    "df_unido.isnull().sum()/df_unido.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29043f45-89a0-4289-9655-78177709c4c1",
   "metadata": {},
   "source": [
    "# Tratando o texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8d3af3-de93-47c7-8872-054dec10a86a",
   "metadata": {},
   "source": [
    "## Bag of words\n",
    "\n",
    "**Vetorizando os dados de teste e treino**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bca01f-6689-4af3-b7bb-76f70bc7f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador = CountVectorizer(max_features=10) # Pegando as 10 dimensões mais aparecem em cada linha do DF\n",
    "bow = vetorizador.fit_transform(df_unido.text)\n",
    "print(bow.shape) # Mostando o tamanho do vetor, foma da matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3465d207-9cf7-4885-88f8-a846add34f70",
   "metadata": {},
   "source": [
    "**Conclusão**\n",
    "\n",
    "Cada resenha do corpus foi representada por um vetor de 10 dimensões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f649554d-c0b5-4d06-b595-ab542f4ee706",
   "metadata": {},
   "source": [
    "Após o processo de bag of words foi retornado uma matriz esparsa tamanho 2x2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251ac4f9-f26e-478c-8ac0-a9fa2cc786cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizador.get_feature_names()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd5cfd-48ad-4a54-a6e2-fa3d384a255e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando o DF com o sparse DataFrame do sklearn. Ele irá interpretar e plotar a matriz \n",
    "matriz_esparsa = pd.DataFrame.sparse.from_spmatrix(bow, columns=vetorizador.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3cec995-edd7-4337-93a6-043cc5fee470",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz_esparsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafee8ac-6bc5-4815-8208-0f5cce8deb68",
   "metadata": {},
   "source": [
    "## Dividindo o DF em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b8a3d-5cfd-4db3-8650-e90c1a69e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passando como parâmetro a coluna de classificão \"clf_num\" e o Bag of words\n",
    "X_train, X_test, y_train, y_test = train_test_split(bow, df_unido.clf_num,random_state=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b78993c-9dd4-4fc9-814c-75f82dd9eabb",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9687d16-e108-439c-87d8-03c5b88fb5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressao_logistica = LogisticRegression()\n",
    "model = regressao_logistica.fit(X_train, y_train)\n",
    "predicted = regressao_logistica.predict(X_test)\n",
    "print(\"Regressão Logística:\", model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444488f2-a39c-4bbf-83e7-863a37f8749a",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "O modelo consegue obter uma taxa de acerto das predições de 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08368c1-5c85-4d77-a19b-54feff7a536c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo de todas as métricas\n",
    "print(\"Acurácia:\", model.score(X_test, y_test))\n",
    "print(\"Kappa:\", metrics.cohen_kappa_score(y_test, predicted))\n",
    "print(\"Todas:\", metrics.precision_recall_fscore_support(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5206348-d27e-42ef-bb70-6caed1669223",
   "metadata": {},
   "source": [
    "## Matriz de Confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74564a7-4f2d-4d74-b41e-b421759e43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo Matriz de Confusão\n",
    "matriz_confusao = metrics.confusion_matrix(y_test, predicted)\n",
    "print(matriz_confusao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34d26a6-7613-463f-8d44-5aaa27995590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotando Matriz de Confusão\n",
    "plt.figure(figsize=(9,9))\n",
    "sns.heatmap(matriz_confusao, annot=True, fmt=\".3f\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "plt.ylabel('Rótulo atual');\n",
    "plt.xlabel('Rótulo previsto');\n",
    "all_sample_title = 'Accuracy Score: {0}'. format(model.score(X_test, y_test))\n",
    "plt.title(all_sample_title, size = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf88668f-be74-43ed-8b83-d690aabfbbf4",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "As métricas acima foram calculadas basedas nas 10 dimensões mais frequentes em cada linha do DF, isto nos mostra que as palavras que mais aparecem neste recorte do DataFrame são conectivos (artigos, pronome demostrativo, preposições e parte de links) que não acrescentam neste momento de análise relevência semântica o que justifica o baixo valor de acuracácia e demais métricas. Portanto, é necessário realizar a retirada destas palavras através de técnicas de remoção de stopwords para que os valores sejam melhorados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d2a451-7105-43a4-9ec4-256f13887e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para classificação do texto\n",
    "# Onde: df_texto = df_unido, coluna_text = text, coluna_classificacao = clf_num do DF original\n",
    "\n",
    "def classificacao_texto(df_texto, coluna_text, coluna_classificacao):\n",
    "    vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "    bow = vetorizar.fit_transform(df_texto[coluna_text])\n",
    "    \n",
    "# Dividindo em treino e teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(bow, df_texto[coluna_classificacao],random_state=50)\n",
    "\n",
    "# Regressão Logística\n",
    "    regressao_logistica = LogisticRegression()\n",
    "    regressao_logistica.fit(X_train, y_train)\n",
    "    return regressao_logistica.score(X_test, y_test)\n",
    "\n",
    "# Chamada da função     \n",
    "print(classificacao_texto(df_unido, \"text\", \"clf_num\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ef281c-e5e3-4977-aa4c-265169758dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando listcomprehension para armazenar na variável \"palavras\" todas as frases do df_unido para mais adiante plotar a wordcloud\n",
    "# O \"join\" foi utilizado para juntar as frases e separar por espaço\n",
    "palavras = ' '.join([texto for texto in df_unido.text]) \n",
    "# Verificando o tamanho da lista\n",
    "len(palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9698003f-2509-4886-86b7-e3ed7d5ce1cc",
   "metadata": {},
   "source": [
    "## WordCLoud | Nuvem de Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dcb365-38b4-4da7-b0ef-3166a46cd4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando a nuvem de palavras\n",
    "word_cloud = WordCloud(width=800, height=500,\n",
    "                      max_font_size=110,\n",
    "                      collocations=False, # para calcular as palavras pela frequência\n",
    "                      background_color=\"white\",\n",
    "                      ).generate(palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650cd234-9da7-4dec-a432-624caab9dda9",
   "metadata": {},
   "source": [
    "**Plotando a imagem da nuvem de palavras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b5fc6-84b5-4381-94ab-d445f2d12e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo o tamamnho da imagem\n",
    "plt.figure(figsize=(10,7)) \n",
    "# O conteúdo da imagem é o que está armazenado na variável \"word_cloud\". \n",
    "# O parâmetro interpolation setado em 'bilinear' torna a visualização mais nítida\n",
    "plt.imshow(word_cloud, interpolation='bilinear') \n",
    "# Removendo a numeraçao dos eixos x e y\n",
    "plt.axis(\"off\") \n",
    "# Exibindo a imagem\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f284780-4771-4a29-9fa4-cf40089a1409",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "No primeiro momento observa-se que a palavra filme \"`movie`\" tem bastante relevância dentro do corpus, no entanto há muitas palavras que não nos dão muitas informações. Por isso, podemos como estratégia para melhorar a análise, plotar as wordclouds separadas pelos sentimentos negativos e positivos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909ea1c9-df7b-4c8e-bd47-b9a24c3c1d4b",
   "metadata": {},
   "source": [
    "**Visualização da wordcloud para frases positivas e negativas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f85da-7c48-4c45-a8ea-2d72ccc21834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando todas as sentenças classificadas com sentimento positivo :\"pos\", \"1\"\n",
    "df_unido.query(\"sentiment == 'pos'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba55d24-eae3-4129-8de5-a37e7a41ea14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf0078f-2ea8-409e-a26e-206d98aa9c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consultando todas as sentenças classificadas com sentimento negativo :\"neg\", \"0\"\n",
    "df_unido.query(\"sentiment == 'neg'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91c5d72-9f17-4e30-9cd2-6a42b9c4a0e2",
   "metadata": {},
   "source": [
    "## Função para gerar as nuvens de palavras separadas por sentimento negativo e positivo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd3b571-ec47-4392-b969-3fa99e305145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que irá retornar somente os sentimentos negativos para em seguida ser plotado na wordcloud\n",
    "def nuvem_negativa(df_texto, coluna_text):\n",
    "    texto_negativo = df_texto.query(\"sentiment == 'neg'\")\n",
    "    palavras = ' '.join([texto for texto in texto_negativo[coluna_text]]) \n",
    "\n",
    "\n",
    "    # Gerando a nuvem de palavras\n",
    "    word_cloud = WordCloud(width=800, height=500,\n",
    "                          max_font_size=110,\n",
    "                          collocations=False,  # Collocations setado como False para calcular as palavras pela frequência\n",
    "                          background_color=\"white\").generate(palavras)\n",
    "    \n",
    "    # Plotando a imagem\n",
    "    plt.figure(figsize=(10,7)) \n",
    "    plt.imshow(word_cloud, interpolation='bilinear') \n",
    "    plt.axis(\"off\") \n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e43d1-7474-424e-94c0-0b39974b5d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotanto somente os sentimentos negativos da coluna \"text\"\n",
    "nuvem_negativa(df_unido, \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68083c01-76f1-4ceb-b139-6aecfed7a4d4",
   "metadata": {},
   "source": [
    "**Análises**\n",
    "\n",
    "\n",
    "Observa-se ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ddd3eb-763a-4ef6-a916-8d8b239b4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função que irá retornar somente os sentimentos positivos para em seguida ser plotado na wordcloud\n",
    "def nuvem_positiva(df_texto, coluna_text):\n",
    "    texto_positivo = df_texto.query(\"sentiment == 'pos'\")\n",
    "    palavras = ' '.join([texto for texto in texto_positivo[coluna_text]]) \n",
    "\n",
    "\n",
    "    # Gerando a nuvem de palavras\n",
    "    word_cloud = WordCloud(width=800, height=500,\n",
    "                          max_font_size=110,\n",
    "                          collocations=False, # Collocations setado como False para calcular as palavras pela frequência\n",
    "                          background_color=\"white\").generate(palavras)\n",
    "    \n",
    "    # Plotando a imagem\n",
    "    plt.figure(figsize=(10,7)) \n",
    "    plt.imshow(word_cloud, interpolation='bilinear') \n",
    "    plt.axis(\"off\") # \"axis\" setado como \"off\" para não aparecer os números na wordcloud\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6848360e-757e-480c-8bd6-c6018b5dc74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotanto somente os sentimentos positivos da coluna \"text\"\n",
    "nuvem_positiva(df_unido, \"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab96481-bbf7-437f-8217-04fd880bebaf",
   "metadata": {},
   "source": [
    "**Análises**\n",
    "\n",
    "\n",
    "Observa-se..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928ac967",
   "metadata": {},
   "source": [
    "# Trabalhando com NLTK \n",
    "\n",
    "### TOKENIZAÇÃO\n",
    "\n",
    "Calculando a frequência de cada palavras atavés da técnica de *`tokenização`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8445e265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenização de todo o corpus (separação por palavras) \n",
    "token_espaco = tokenize.WhitespaceTokenizer()\n",
    "token_df = token_espaco.tokenize(palavras) # variável \"palavras\" armazenda todas as frases do meu corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0262c324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando a frequência\n",
    "freq_palavras = nltk.FreqDist(token_df)\n",
    "freq_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cb30f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um DF para armazenar as palavras e suas frequências de ocorrência no corpus para melhorar a visualização\n",
    "df_freq = pd.DataFrame({\"palavra\": list(freq_palavras.keys()),\n",
    "                       \"frequencia\": list(freq_palavras.values())})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a25901",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando o DataFrame com a frequência das palavras\n",
    "df_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd229fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrando as 10 palavras com maior frequência utilizando o método \"nlargest\"\n",
    "df_freq.nlargest(columns = \"frequencia\", n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d92da3",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "Ao impirmir as palavras com maior frequência no DataFrame constata-se que são palavras de classe gramatical (artigo, conjunção, preposição, verbo, pronome pessoal e pronome demonstrativo) que em sua maioria não possuem relevância semântica suficiente que justifique sua permanência no copus de análise. Portanto, deve-se proceder com a remoção através da técnica de remoção de stopwors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1446f22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma(df_texto, coluna_text, quantidade):\n",
    "     \n",
    "    palavras = ' '.join([texto for texto in df_texto[coluna_text]])     \n",
    "    token_df = token_espaco.tokenize(palavras)\n",
    "    freq_palavras = nltk.FreqDist(token_df)\n",
    "    df_freq = pd.DataFrame({\"palavra\": list(freq_palavras.keys()),\n",
    "                       \"frequencia\": list(freq_palavras.values())})\n",
    "   \n",
    "    df_freq = df_freq.nlargest(columns = \"frequencia\", n = quantidade)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = sns.barplot(data = df_freq, x = \"palavra\", y = \"frequencia\")\n",
    "    ax.set(ylabel = \"contagem\")\n",
    "    plt.show()\n",
    "               \n",
    "\n",
    "histograma(df_unido, \"text\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c03cc06",
   "metadata": {},
   "source": [
    "## Removendo Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba2de51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b26fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armazenando na variável \"stopwords\" a lista de stopwords do corpus do inglês\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "# Armazena a frase tokenizada (que foi processada), em uma lista\n",
    "frase_processada = list()\n",
    "\n",
    "# Retiranto as stopwords de cada frase/linha da coluna \"text\" do DataFrame \n",
    "for resenha in df_unido.text:\n",
    "    frase_nova = list()\n",
    "    palavra_texto = token_espaco.tokenize(resenha)\n",
    "    for palavra in palavra_texto:\n",
    "        if palavra not in stopwords:\n",
    "            frase_nova.append(palavra)\n",
    "            \n",
    "    frase_processada.append(' '. join(frase_nova)) # Juntando todas as frases\n",
    "    \n",
    "# Criando uma coluna com a frase processada, isto é, após a remoção das stopwords\n",
    "df_unido[\"processamento_1\"] = frase_processada    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fd96d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00e2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função 'classificacao_texto' na coluna \"processamento_1\" utilizando como base a coluna da classificação dos sentimentos 'clf_num' \n",
    "acuracia_processamento_1 = classificacao_texto(df_unido, \"processamento_1\", \"clf_num\")\n",
    "print(acuracia_processamento_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465bb0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma - Plotando as palavras mais frequentes após a remoção das stopwords\n",
    "histograma(df_unido, \"processamento_1\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0374de3",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "Após a remoção das stopwords e passando para a função \"`classificacao_texto`\" como parâmetro a coluna \"`processamento_1`\" que contém as frases processadas/tratadas, podemos fazer um comparativo dos resultados obtidos na primeira classificação com esta última. Observamos que a primeira (Regressão Logística) obteve a acurácia de `0.65072` e a segunda o valor de `0.71352`, um aumento de `0,0628` no total de acerto. Estes resultados poderão ser melhorados conforme avançamos no tratamento do corpus, esta foi somente a primeira parte. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1094be5",
   "metadata": {},
   "source": [
    "## Removendo as pontuações das palavras do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae35459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pontuações que serão removidas do corpus \n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d07dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pontuacao = tokenize.WordPunctTokenizer()\n",
    "token_frase = token_pontuacao.tokenize(palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db159fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserindo as pontuações em uma lista cada um sendo separado como elemento único\n",
    "pontuacao = list()\n",
    "for ponto in punctuation:\n",
    "    pontuacao.append(ponto)\n",
    "    \n",
    "# Inserindo a pontuação na lista de stopwords\n",
    "pontuacao_stopwords = pontuacao + stopwords\n",
    "\n",
    "# Iterando sobre a lista (texto) que já passou pelo primeiro tratamento e que está armazenado na coluna \"processamento_1\" \n",
    "frase_processada2 = list()\n",
    "for resenha in df_unido[\"processamento_1\"]:\n",
    "    frase_nova2 = list()\n",
    "    palavras_texto2 = token_pontuacao.tokenize(resenha)\n",
    "    for palavra in palavras_texto2:\n",
    "        if palavra not in pontuacao_stopwords:\n",
    "            frase_nova2.append(palavra)\n",
    "    frase_processada2.append(' '.join(frase_nova2))\n",
    "            \n",
    "df_unido[\"processamento_2\"] = frase_processada2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af69045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analisando se a remoção das stopwords funcionou\n",
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85f6102",
   "metadata": {},
   "source": [
    "**Comparando a remoção das pontuações na linha de índice \"0\" das colunas \"processamento_1 e processamento_2\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d133c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido[\"processamento_1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido[\"processamento_2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db986210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotanto somente os sentimentos negativos da coluna \"text\"\n",
    "nuvem_negativa(df_unido, \"processamento_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6af000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotanto somente os sentimentos positivos da coluna \"text\"\n",
    "nuvem_positiva(df_unido, \"processamento_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma(df_unido, \"processamento_2\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34005f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando a função 'classificacao_texto' na coluna \"processamento_2\" utilizando como base a coluna da classificação dos sentimentos 'clf_num' \n",
    "acuracia_processamento_2 = classificacao_texto(df_unido, \"processamento_2\", \"clf_num\")\n",
    "print(\"Acurácia 2: \", acuracia_processamento_2)\n",
    "print(\"Acurácia 1: \" , acuracia_processamento_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cb8ced",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "Podemos observar no gráfico acima que após o processso de remoção das pontuações não houve uma mudança significativa no cálculo da acurácia, pelo contrário, houve uma leve redução nesse valor indo de `0.71352` para `0.71288`. \n",
    "\n",
    "Observando as posições das 10 palavras mais frequentes do dataset percebemos que a palavra `\"I\"` saiu da primeira posição na ordem de maior frequência cedendo espaço para `\"br\"` que vinha logo em seguida. Já a palavra `\"like\"` passou da sétima posição para a décima do histograma em ordem de maior frequência."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f1ea7d",
   "metadata": {},
   "source": [
    "# Normalização de textos \n",
    "\n",
    "Passando o DataFrame para minúsculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc00d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_processada3 = list()\n",
    "for resenha in df_unido[\"processamento_2\"]:\n",
    "    frase_nova3 = list()\n",
    "    resenha = resenha.lower()\n",
    "    palavras_texto3 = token_pontuacao.tokenize(resenha)\n",
    "    for palavra in palavras_texto3:\n",
    "        if palavra not in pontuacao_stopwords:\n",
    "            frase_nova3.append(palavra)\n",
    "    frase_processada3.append(' '.join(frase_nova3))\n",
    "            \n",
    "df_unido[\"processamento_3\"] = frase_processada3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d29965",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730a651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido[\"text\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69f86c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido[\"processamento_3\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115a1ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma(df_unido, \"processamento_3\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93374bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvem_negativa(df_unido, \"processamento_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5592297",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvem_positiva(df_unido, \"processamento_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5fc2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_processamento_3 = classificacao_texto(df_unido, \"processamento_3\", \"clf_num\")\n",
    "print(\"Acurácia 3: \", acuracia_processamento_3)\n",
    "print(\"Acurácia 2: \", acuracia_processamento_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04b1d4b",
   "metadata": {},
   "source": [
    "**Análise**\n",
    "\n",
    "Através do histograma referente ao `\"tratamento_3\"`, isto é, a tranformação das palavras maiúsculas do corpus para palavras minúscula, podemos perceber que, por exemplo, a palavra `\"film\"` que no `\"processamento_2\"` estava na posição 7 na ordem de maior frequência do DataFrame, subiu para a posição 5. Isto nos mostra que a sua relevância está crescendo e destacando-se nos gráficos como podemos perceber também na nuvem de palavras negativas e positivas. Além da palavra \"film\" outras começam a aparecer com maior destaque nas wordclouds, a saber, `\"worse\" e \"horror\"` (sentimentos negativos) e `\"great\" e \"good\"` (sentimentos positivos).\n",
    "\n",
    "Com  relação a acurácia dos dois últimos passos de tratamento do texto, isto é, do \"tratamento_2\" para o \"tratamento_3\" houve uma melhora de apenas cinco décimos na taxa de acerto. Comparemos logo em seguida: `Acurácia 3:  0.71752`|\n",
    "`Acurácia 2:  0.71288`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af22009",
   "metadata": {},
   "source": [
    "## Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ebf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3055cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_processada4 = list()\n",
    "for resenha in df_unido[\"processamento_3\"]:\n",
    "    frase_nova4 = list()\n",
    "    palavras_texto4 = token_pontuacao.tokenize(resenha)\n",
    "    for palavra in palavras_texto4:\n",
    "        if palavra not in pontuacao_stopwords:\n",
    "            frase_nova4.append(stemmer.stem(palavra))\n",
    "    frase_processada4.append(' '.join(frase_nova4))\n",
    "            \n",
    "df_unido[\"processamento_4\"] = frase_processada4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a551b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dd1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "histograma(df_unido, \"processamento_4\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25341f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_processamento_4 = classificacao_texto(df_unido, \"processamento_4\", \"clf_num\")\n",
    "print(\"Acurácia 4: \", acuracia_processamento_4)\n",
    "print(\"Acurácia 3: \", acuracia_processamento_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fd2b93",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
